{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_occurence_matrix(text, target=None, stop_words=None, binary=True, preprocess_text=False):  \n",
    "    '''\n",
    "    Output is messages x (unique) words\n",
    "    \n",
    "    If binary=True, then each element represents if the word is in the message or not.\n",
    "    Otherwise, it represents the count of how many times that word appears in that message.\n",
    "    ''' \n",
    "    if target:\n",
    "        text = list(filter(lambda x : target in x, text)) #Filter comments in which target word is present\n",
    "        \n",
    "    preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor()   \n",
    "    if stop_words:        \n",
    "        stop_words = [preprocessor(word) for word in stop_words] #preprocesses stop words\n",
    "    if preprocess_text:\n",
    "        text = [preprocessor(msg) for msg in text] #preprocesses text\n",
    "        \n",
    "    #calculates word count for each message\n",
    "    vectorizer = CountVectorizer(strip_accents='unicode', stop_words=stop_words, binary=binary)\n",
    "    X = vectorizer.fit_transform(text).toarray()\n",
    "    \n",
    "    labels = vectorizer.get_feature_names()\n",
    "    \n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('../../dados/youtube/comentarios1.csv')\n",
    "stop_words = [word.rstrip() for word in open('../stopwords.txt')]\n",
    "\n",
    "preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor() \n",
    "#lowercase and strip accents\n",
    "stop_words = [preprocessor(word) for word in stop_words]\n",
    "#English and Spanish Words\n",
    "stop_words.extend(['you', 'good', 'the', 'to', 'live', 'very', 'your', 'work', 'is', 'my', 'from', 'love', 'and', \n",
    "                   'in', 'thank', 'informative', 'are', 'of', 'un', 'english', 'what', 'mi', 'hello', 'el', \n",
    "                   'but', 'doctor'])\n",
    "#Nomes Próprios\n",
    "stop_words.extend(['drauzio', 'varella', 'lucy', 'kerr', 'julio', 'pereira','fernando', 'pinto', 'gomes', 'lair', \n",
    "                   'ribeiro', 'alvaro', 'galvao', 'felipe', 'ades', 'gomez', 'alain', 'dutra'])\n",
    "#Pronomes e preposições\n",
    "stop_words.extend(['pra', 'vc', 'todos', 'tudo', 'cada', 'nada', 'sobre'])\n",
    "#Conjunções\n",
    "stop_words.extend(['porque', 'pois', 'pq'])\n",
    "#Advérbios\n",
    "stop_words.extend(['assim', 'bem', 'ainda', 'agora', 'sim', 'sempre', 'aqui', 'la', 'tbm', 'ai', 'hoje'])\n",
    "#Verbos frequentes\n",
    "stop_words.extend(['vai', 'ser', 'ter', 'ta', 'fazer', 'fiz', 'faz', 'vou'])\n",
    "#Outros\n",
    "stop_words.extend(['boa', 'bom', 'obrigado', 'ola'])\n",
    "\n",
    "#Remove urls\n",
    "comments['text'] = [re.sub(r'http\\S+', '', msg) for msg in comments['text']]\n",
    "#Remove emails\n",
    "comments['text'] = [re.sub(r'\\S*@\\S*\\s?', '', msg) for msg in comments['text']]\n",
    "#lowercase and strip accents\n",
    "comments['text'] = [preprocessor(msg) for msg in comments['text']]\n",
    "#remove stopwords and punctuation\n",
    "comments['text'] = [' '.join([word for word in RegexpTokenizer(r'\\w+').tokenize(msg) if not word in stop_words])\n",
    "                    for msg in comments['text']]\n",
    "# Remove new line characters\n",
    "comments['text'] = [re.sub(r'\\s+', ' ', msg) for msg in comments['text']]\n",
    "# Remove distracting single quotes\n",
    "comments['text'] = [re.sub(r\"\\'\", \"\", msg) for msg in comments['text']]\n",
    "#Remove special characters\n",
    "comments['text'] = [re.sub(r'([^a-zA-Z0-9\\s]+?)', '', msg) for msg in comments['text']]\n",
    "\n",
    "#Remove words with freq == 1\n",
    "fdist = FreqDist(RegexpTokenizer(r'\\w+').tokenize(' '.join(comments['text'])))\n",
    "freq_filter = filter(lambda x: x[1] == 1, fdist.items())\n",
    "fdist = [t[0] for t in freq_filter]\n",
    "comments['text'] = [' '.join([word for word in RegexpTokenizer(r'\\w+').tokenize(msg) if not word in fdist])\n",
    "                    for msg in comments['text']]\n",
    "\n",
    "N = 30 #Consider only the N most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_by_channel = []\n",
    "channels = []\n",
    "for channel, group in comments.groupby('uploader'):\n",
    "    channel_comments = ' '.join(group['text'])\n",
    "    comments_by_channel.append(channel_comments)\n",
    "    channels.append(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencia relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Em relação ao total\n",
    "Não usar essa. Deixei aqui por precaução.\n",
    "\n",
    "Aqui foi usada a distribuição de probabilidade conjunta das palavras e canais, i.e., $p(a_i, c_j) = P(A=a_i, C= C_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0023, dias)</td>\n",
       "      <td>(0.0007, dias)</td>\n",
       "      <td>(0.0001, sintomas)</td>\n",
       "      <td>(0.0003, dr)</td>\n",
       "      <td>(0.0007, dr)</td>\n",
       "      <td>(0.0035, dr)</td>\n",
       "      <td>(0.0061, dias)</td>\n",
       "      <td>(0.0025, ivermectina)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0017, tomar)</td>\n",
       "      <td>(0.0005, ivermectina)</td>\n",
       "      <td>(0.0001, dor)</td>\n",
       "      <td>(0.0001, parabens)</td>\n",
       "      <td>(0.0003, virus)</td>\n",
       "      <td>(0.0032, virus)</td>\n",
       "      <td>(0.0042, deus)</td>\n",
       "      <td>(0.0018, dias)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0016, ivermectina)</td>\n",
       "      <td>(0.0004, tomar)</td>\n",
       "      <td>(0.0001, dias)</td>\n",
       "      <td>(0.0001, noite)</td>\n",
       "      <td>(0.0002, deus)</td>\n",
       "      <td>(0.0032, video)</td>\n",
       "      <td>(0.0042, cheiro)</td>\n",
       "      <td>(0.0016, dra)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0013, dr)</td>\n",
       "      <td>(0.0004, dr)</td>\n",
       "      <td>(0.0001, dia)</td>\n",
       "      <td>(0.0000, zzzzzz)</td>\n",
       "      <td>(0.0001, video)</td>\n",
       "      <td>(0.0028, pessoas)</td>\n",
       "      <td>(0.0041, olfato)</td>\n",
       "      <td>(0.0013, tomar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0012, comprimidos)</td>\n",
       "      <td>(0.0004, comprimidos)</td>\n",
       "      <td>(0.0001, deus)</td>\n",
       "      <td>(0.0000, zz)</td>\n",
       "      <td>(0.0001, verdade)</td>\n",
       "      <td>(0.0020, casa)</td>\n",
       "      <td>(0.0040, paladar)</td>\n",
       "      <td>(0.0011, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0010, deus)</td>\n",
       "      <td>(0.0004, 15)</td>\n",
       "      <td>(0.0001, deu)</td>\n",
       "      <td>(0.0000, zumbis)</td>\n",
       "      <td>(0.0001, ver)</td>\n",
       "      <td>(0.0017, pode)</td>\n",
       "      <td>(0.0032, dor)</td>\n",
       "      <td>(0.0010, covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0009, pode)</td>\n",
       "      <td>(0.0003, dose)</td>\n",
       "      <td>(0.0001, covid)</td>\n",
       "      <td>(0.0000, zumbido)</td>\n",
       "      <td>(0.0001, sistema)</td>\n",
       "      <td>(0.0017, dia)</td>\n",
       "      <td>(0.0027, sinto)</td>\n",
       "      <td>(0.0009, comprimidos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0009, dia)</td>\n",
       "      <td>(0.0002, pode)</td>\n",
       "      <td>(0.0000, zzzzzz)</td>\n",
       "      <td>(0.0000, zumbi)</td>\n",
       "      <td>(0.0001, senhor)</td>\n",
       "      <td>(0.0016, senhor)</td>\n",
       "      <td>(0.0026, sentir)</td>\n",
       "      <td>(0.0008, pode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0007, dra)</td>\n",
       "      <td>(0.0002, pessoas)</td>\n",
       "      <td>(0.0000, zz)</td>\n",
       "      <td>(0.0000, zuera)</td>\n",
       "      <td>(0.0001, saude)</td>\n",
       "      <td>(0.0016, dias)</td>\n",
       "      <td>(0.0026, gosto)</td>\n",
       "      <td>(0.0008, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0007, dose)</td>\n",
       "      <td>(0.0002, parabens)</td>\n",
       "      <td>(0.0000, zumbis)</td>\n",
       "      <td>(0.0000, zueira)</td>\n",
       "      <td>(0.0001, sabe)</td>\n",
       "      <td>(0.0016, deus)</td>\n",
       "      <td>(0.0025, sintomas)</td>\n",
       "      <td>(0.0008, dia)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dr. Alain Dutra      Dr. Alvaro Galvão Dr. Felipe Ades MD PhD  \\\n",
       "0         (0.0023, dias)         (0.0007, dias)     (0.0001, sintomas)   \n",
       "1        (0.0017, tomar)  (0.0005, ivermectina)          (0.0001, dor)   \n",
       "2  (0.0016, ivermectina)        (0.0004, tomar)         (0.0001, dias)   \n",
       "3           (0.0013, dr)           (0.0004, dr)          (0.0001, dia)   \n",
       "4  (0.0012, comprimidos)  (0.0004, comprimidos)         (0.0001, deus)   \n",
       "5         (0.0010, deus)           (0.0004, 15)          (0.0001, deu)   \n",
       "6         (0.0009, pode)         (0.0003, dose)        (0.0001, covid)   \n",
       "7          (0.0009, dia)         (0.0002, pode)       (0.0000, zzzzzz)   \n",
       "8          (0.0007, dra)      (0.0002, pessoas)           (0.0000, zz)   \n",
       "9         (0.0007, dose)     (0.0002, parabens)       (0.0000, zumbis)   \n",
       "\n",
       "   Dr. Fernando Gomes Dr. Lair Ribeiro Oficial    Drauzio Varella  \\\n",
       "0        (0.0003, dr)             (0.0007, dr)       (0.0035, dr)   \n",
       "1  (0.0001, parabens)          (0.0003, virus)    (0.0032, virus)   \n",
       "2     (0.0001, noite)           (0.0002, deus)    (0.0032, video)   \n",
       "3    (0.0000, zzzzzz)          (0.0001, video)  (0.0028, pessoas)   \n",
       "4        (0.0000, zz)        (0.0001, verdade)     (0.0020, casa)   \n",
       "5    (0.0000, zumbis)            (0.0001, ver)     (0.0017, pode)   \n",
       "6   (0.0000, zumbido)        (0.0001, sistema)      (0.0017, dia)   \n",
       "7     (0.0000, zumbi)         (0.0001, senhor)   (0.0016, senhor)   \n",
       "8     (0.0000, zuera)          (0.0001, saude)     (0.0016, dias)   \n",
       "9    (0.0000, zueira)           (0.0001, sabe)     (0.0016, deus)   \n",
       "\n",
       "  Julio Pereira - Neurocirurgião              Lucy Kerr  \n",
       "0                 (0.0061, dias)  (0.0025, ivermectina)  \n",
       "1                 (0.0042, deus)         (0.0018, dias)  \n",
       "2               (0.0042, cheiro)          (0.0016, dra)  \n",
       "3               (0.0041, olfato)        (0.0013, tomar)  \n",
       "4              (0.0040, paladar)         (0.0011, deus)  \n",
       "5                  (0.0032, dor)        (0.0010, covid)  \n",
       "6                (0.0027, sinto)  (0.0009, comprimidos)  \n",
       "7               (0.0026, sentir)         (0.0008, pode)  \n",
       "8                (0.0026, gosto)           (0.0008, dr)  \n",
       "9             (0.0025, sintomas)          (0.0008, dia)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "\n",
    "X = X / X.sum()\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 palavras com maior desvio padrão entre os canais:\n",
      "\n",
      "[('dias', '0.0019'), ('cheiro', '0.0014'), ('olfato', '0.0013'), ('paladar', '0.0013'), ('deus', '0.0013'), ('dr', '0.0010'), ('virus', '0.0010'), ('dor', '0.0010'), ('video', '0.0010'), ('pessoas', '0.0009'), ('sinto', '0.0009'), ('ivermectina', '0.0009'), ('sentir', '0.0009'), ('gosto', '0.0008'), ('dia', '0.0008'), ('sintomas', '0.0008'), ('covid', '0.0007'), ('casa', '0.0006'), ('febre', '0.0006'), ('pode', '0.0006'), ('cabeca', '0.0006'), ('tomar', '0.0006'), ('dra', '0.0005'), ('senhor', '0.0005'), ('medico', '0.0005'), ('falta', '0.0005'), ('fiquei', '0.0005'), ('doutor', '0.0005'), ('ar', '0.0005'), ('comprimidos', '0.0004')]\n"
     ]
    }
   ],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Em relação ao canal\n",
    "Foi obtida a distribuição de probabilidade das palavras em cada canal $C_k$, i.e., $p(a_i|C_k) = P(A=a_i|C_k)$. \n",
    "Com isso, podemos fazer corretamente comparações entre os canais. Foram, então, selecionadas as palavras cuja ocorrência mais se difere entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras com maior frequência relativa em cada canal:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0195, dias)</td>\n",
       "      <td>(0.0201, dias)</td>\n",
       "      <td>(0.0288, dias)</td>\n",
       "      <td>(0.0616, dr)</td>\n",
       "      <td>(0.0272, dr)</td>\n",
       "      <td>(0.0097, dr)</td>\n",
       "      <td>(0.0210, dias)</td>\n",
       "      <td>(0.0158, ivermectina)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0141, tomar)</td>\n",
       "      <td>(0.0148, ivermectina)</td>\n",
       "      <td>(0.0164, dia)</td>\n",
       "      <td>(0.0189, noite)</td>\n",
       "      <td>(0.0108, virus)</td>\n",
       "      <td>(0.0086, virus)</td>\n",
       "      <td>(0.0143, deus)</td>\n",
       "      <td>(0.0112, dias)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0133, ivermectina)</td>\n",
       "      <td>(0.0138, dr)</td>\n",
       "      <td>(0.0164, covid)</td>\n",
       "      <td>(0.0186, parabens)</td>\n",
       "      <td>(0.0070, deus)</td>\n",
       "      <td>(0.0086, video)</td>\n",
       "      <td>(0.0143, cheiro)</td>\n",
       "      <td>(0.0101, dra)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0114, dr)</td>\n",
       "      <td>(0.0135, 15)</td>\n",
       "      <td>(0.0158, sintomas)</td>\n",
       "      <td>(0.0071, lindo)</td>\n",
       "      <td>(0.0056, saude)</td>\n",
       "      <td>(0.0077, pessoas)</td>\n",
       "      <td>(0.0142, olfato)</td>\n",
       "      <td>(0.0080, tomar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0101, comprimidos)</td>\n",
       "      <td>(0.0129, comprimidos)</td>\n",
       "      <td>(0.0152, dor)</td>\n",
       "      <td>(0.0068, dia)</td>\n",
       "      <td>(0.0050, video)</td>\n",
       "      <td>(0.0054, casa)</td>\n",
       "      <td>(0.0138, paladar)</td>\n",
       "      <td>(0.0070, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0084, deus)</td>\n",
       "      <td>(0.0125, tomar)</td>\n",
       "      <td>(0.0142, deu)</td>\n",
       "      <td>(0.0061, deus)</td>\n",
       "      <td>(0.0048, pessoas)</td>\n",
       "      <td>(0.0047, dia)</td>\n",
       "      <td>(0.0108, dor)</td>\n",
       "      <td>(0.0065, covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0077, dia)</td>\n",
       "      <td>(0.0079, dose)</td>\n",
       "      <td>(0.0124, deus)</td>\n",
       "      <td>(0.0059, obrigada)</td>\n",
       "      <td>(0.0045, mundo)</td>\n",
       "      <td>(0.0045, senhor)</td>\n",
       "      <td>(0.0091, sinto)</td>\n",
       "      <td>(0.0056, comprimidos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0076, pode)</td>\n",
       "      <td>(0.0068, kg)</td>\n",
       "      <td>(0.0108, positivo)</td>\n",
       "      <td>(0.0054, doutor)</td>\n",
       "      <td>(0.0045, medico)</td>\n",
       "      <td>(0.0045, pode)</td>\n",
       "      <td>(0.0090, sentir)</td>\n",
       "      <td>(0.0054, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0062, dose)</td>\n",
       "      <td>(0.0067, parabens)</td>\n",
       "      <td>(0.0096, teste)</td>\n",
       "      <td>(0.0050, amor)</td>\n",
       "      <td>(0.0042, covid)</td>\n",
       "      <td>(0.0045, dias)</td>\n",
       "      <td>(0.0088, gosto)</td>\n",
       "      <td>(0.0053, dia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0061, covid)</td>\n",
       "      <td>(0.0063, pode)</td>\n",
       "      <td>(0.0090, dr)</td>\n",
       "      <td>(0.0042, excelente)</td>\n",
       "      <td>(0.0039, china)</td>\n",
       "      <td>(0.0042, deus)</td>\n",
       "      <td>(0.0084, sintomas)</td>\n",
       "      <td>(0.0051, pode)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dr. Alain Dutra      Dr. Alvaro Galvão Dr. Felipe Ades MD PhD  \\\n",
       "0         (0.0195, dias)         (0.0201, dias)         (0.0288, dias)   \n",
       "1        (0.0141, tomar)  (0.0148, ivermectina)          (0.0164, dia)   \n",
       "2  (0.0133, ivermectina)           (0.0138, dr)        (0.0164, covid)   \n",
       "3           (0.0114, dr)           (0.0135, 15)     (0.0158, sintomas)   \n",
       "4  (0.0101, comprimidos)  (0.0129, comprimidos)          (0.0152, dor)   \n",
       "5         (0.0084, deus)        (0.0125, tomar)          (0.0142, deu)   \n",
       "6          (0.0077, dia)         (0.0079, dose)         (0.0124, deus)   \n",
       "7         (0.0076, pode)           (0.0068, kg)     (0.0108, positivo)   \n",
       "8         (0.0062, dose)     (0.0067, parabens)        (0.0096, teste)   \n",
       "9        (0.0061, covid)         (0.0063, pode)           (0.0090, dr)   \n",
       "\n",
       "    Dr. Fernando Gomes Dr. Lair Ribeiro Oficial    Drauzio Varella  \\\n",
       "0         (0.0616, dr)             (0.0272, dr)       (0.0097, dr)   \n",
       "1      (0.0189, noite)          (0.0108, virus)    (0.0086, virus)   \n",
       "2   (0.0186, parabens)           (0.0070, deus)    (0.0086, video)   \n",
       "3      (0.0071, lindo)          (0.0056, saude)  (0.0077, pessoas)   \n",
       "4        (0.0068, dia)          (0.0050, video)     (0.0054, casa)   \n",
       "5       (0.0061, deus)        (0.0048, pessoas)      (0.0047, dia)   \n",
       "6   (0.0059, obrigada)          (0.0045, mundo)   (0.0045, senhor)   \n",
       "7     (0.0054, doutor)         (0.0045, medico)     (0.0045, pode)   \n",
       "8       (0.0050, amor)          (0.0042, covid)     (0.0045, dias)   \n",
       "9  (0.0042, excelente)          (0.0039, china)     (0.0042, deus)   \n",
       "\n",
       "  Julio Pereira - Neurocirurgião              Lucy Kerr  \n",
       "0                 (0.0210, dias)  (0.0158, ivermectina)  \n",
       "1                 (0.0143, deus)         (0.0112, dias)  \n",
       "2               (0.0143, cheiro)          (0.0101, dra)  \n",
       "3               (0.0142, olfato)        (0.0080, tomar)  \n",
       "4              (0.0138, paladar)         (0.0070, deus)  \n",
       "5                  (0.0108, dor)        (0.0065, covid)  \n",
       "6                (0.0091, sinto)  (0.0056, comprimidos)  \n",
       "7               (0.0090, sentir)           (0.0054, dr)  \n",
       "8                (0.0088, gosto)          (0.0053, dia)  \n",
       "9             (0.0084, sintomas)         (0.0051, pode)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "#Makes frequencies relative to each channel so that we have the probability distribution of words for each channel\n",
    "X = (X.T / X.sum(axis=1)).T\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "print('Palavras com maior frequência relativa em cada canal:')\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 palavras com maior desvio padrão entre os canais:\n",
      "\n",
      "[('dr', '0.0181'), ('dias', '0.0096'), ('ivermectina', '0.0069'), ('noite', '0.0057'), ('parabens', '0.0054'), ('dor', '0.0054'), ('tomar', '0.0051'), ('comprimidos', '0.0049'), ('olfato', '0.0049'), ('sintomas', '0.0048'), ('paladar', '0.0047'), ('cheiro', '0.0046'), ('deu', '0.0043'), ('covid', '0.0043'), ('15', '0.0042'), ('dia', '0.0038'), ('positivo', '0.0034'), ('dra', '0.0034'), ('deus', '0.0032'), ('sinto', '0.0031'), ('dose', '0.0030'), ('teste', '0.0030'), ('virus', '0.0029'), ('sentir', '0.0029'), ('gosto', '0.0028'), ('exame', '0.0027'), ('kg', '0.0026'), ('cabeca', '0.0025'), ('video', '0.0024'), ('lindo', '0.0023')]\n"
     ]
    }
   ],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Por gênero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genero_df = pd.read_csv('../../dados/youtube/comentarios1_genero_90-100.csv', usecols=['cid', 'genero'])\n",
    "comments = comments.merge(genero_df)\n",
    "\n",
    "comments_by_channel_F = []\n",
    "comments_by_channel_M = []\n",
    "for channel, group in comments.groupby('uploader'):\n",
    "    channel_comments = ' '.join(group[group['genero']=='F']['text'])\n",
    "    comments_by_channel_F.append(channel_comments)\n",
    "    channel_comments = ' '.join(group[group['genero']=='M']['text'])\n",
    "    comments_by_channel_M.append(channel_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras com maior frequência relativa entre mulheres em cada canal:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0187, dias)</td>\n",
       "      <td>(0.0263, dias)</td>\n",
       "      <td>(0.0334, dias)</td>\n",
       "      <td>(0.0744, dr)</td>\n",
       "      <td>(0.0341, dr)</td>\n",
       "      <td>(0.0132, dr)</td>\n",
       "      <td>(0.0226, dias)</td>\n",
       "      <td>(0.0160, ivermectina)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0156, tomar)</td>\n",
       "      <td>(0.0188, dr)</td>\n",
       "      <td>(0.0176, sintomas)</td>\n",
       "      <td>(0.0236, noite)</td>\n",
       "      <td>(0.0103, deus)</td>\n",
       "      <td>(0.0079, virus)</td>\n",
       "      <td>(0.0161, deus)</td>\n",
       "      <td>(0.0136, dias)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0140, ivermectina)</td>\n",
       "      <td>(0.0170, tomar)</td>\n",
       "      <td>(0.0164, covid)</td>\n",
       "      <td>(0.0163, parabens)</td>\n",
       "      <td>(0.0093, virus)</td>\n",
       "      <td>(0.0078, video)</td>\n",
       "      <td>(0.0158, olfato)</td>\n",
       "      <td>(0.0128, dra)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0137, dr)</td>\n",
       "      <td>(0.0156, 15)</td>\n",
       "      <td>(0.0147, deu)</td>\n",
       "      <td>(0.0080, obrigada)</td>\n",
       "      <td>(0.0069, gratidao)</td>\n",
       "      <td>(0.0078, pessoas)</td>\n",
       "      <td>(0.0154, paladar)</td>\n",
       "      <td>(0.0102, tomar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0130, deus)</td>\n",
       "      <td>(0.0152, ivermectina)</td>\n",
       "      <td>(0.0142, dor)</td>\n",
       "      <td>(0.0069, doutor)</td>\n",
       "      <td>(0.0065, obrigada)</td>\n",
       "      <td>(0.0067, casa)</td>\n",
       "      <td>(0.0151, cheiro)</td>\n",
       "      <td>(0.0102, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0093, obrigada)</td>\n",
       "      <td>(0.0127, comprimidos)</td>\n",
       "      <td>(0.0142, dia)</td>\n",
       "      <td>(0.0065, dia)</td>\n",
       "      <td>(0.0052, grande)</td>\n",
       "      <td>(0.0064, obrigada)</td>\n",
       "      <td>(0.0136, dor)</td>\n",
       "      <td>(0.0069, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0086, dia)</td>\n",
       "      <td>(0.0098, obrigada)</td>\n",
       "      <td>(0.0136, deus)</td>\n",
       "      <td>(0.0065, deus)</td>\n",
       "      <td>(0.0050, abencoe)</td>\n",
       "      <td>(0.0063, dia)</td>\n",
       "      <td>(0.0109, sinto)</td>\n",
       "      <td>(0.0067, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0081, comprimidos)</td>\n",
       "      <td>(0.0082, dose)</td>\n",
       "      <td>(0.0130, teste)</td>\n",
       "      <td>(0.0065, amor)</td>\n",
       "      <td>(0.0048, gente)</td>\n",
       "      <td>(0.0063, deus)</td>\n",
       "      <td>(0.0094, sintomas)</td>\n",
       "      <td>(0.0065, covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0078, pode)</td>\n",
       "      <td>(0.0079, deus)</td>\n",
       "      <td>(0.0119, positivo)</td>\n",
       "      <td>(0.0054, excelente)</td>\n",
       "      <td>(0.0048, doutor)</td>\n",
       "      <td>(0.0061, dias)</td>\n",
       "      <td>(0.0092, gosto)</td>\n",
       "      <td>(0.0055, pode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0068, tomei)</td>\n",
       "      <td>(0.0073, doutor)</td>\n",
       "      <td>(0.0085, muita)</td>\n",
       "      <td>(0.0047, adorei)</td>\n",
       "      <td>(0.0047, saude)</td>\n",
       "      <td>(0.0055, senhor)</td>\n",
       "      <td>(0.0091, sentir)</td>\n",
       "      <td>(0.0053, pessoas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dr. Alain Dutra      Dr. Alvaro Galvão Dr. Felipe Ades MD PhD  \\\n",
       "0         (0.0187, dias)         (0.0263, dias)         (0.0334, dias)   \n",
       "1        (0.0156, tomar)           (0.0188, dr)     (0.0176, sintomas)   \n",
       "2  (0.0140, ivermectina)        (0.0170, tomar)        (0.0164, covid)   \n",
       "3           (0.0137, dr)           (0.0156, 15)          (0.0147, deu)   \n",
       "4         (0.0130, deus)  (0.0152, ivermectina)          (0.0142, dor)   \n",
       "5     (0.0093, obrigada)  (0.0127, comprimidos)          (0.0142, dia)   \n",
       "6          (0.0086, dia)     (0.0098, obrigada)         (0.0136, deus)   \n",
       "7  (0.0081, comprimidos)         (0.0082, dose)        (0.0130, teste)   \n",
       "8         (0.0078, pode)         (0.0079, deus)     (0.0119, positivo)   \n",
       "9        (0.0068, tomei)       (0.0073, doutor)        (0.0085, muita)   \n",
       "\n",
       "    Dr. Fernando Gomes Dr. Lair Ribeiro Oficial     Drauzio Varella  \\\n",
       "0         (0.0744, dr)             (0.0341, dr)        (0.0132, dr)   \n",
       "1      (0.0236, noite)           (0.0103, deus)     (0.0079, virus)   \n",
       "2   (0.0163, parabens)          (0.0093, virus)     (0.0078, video)   \n",
       "3   (0.0080, obrigada)       (0.0069, gratidao)   (0.0078, pessoas)   \n",
       "4     (0.0069, doutor)       (0.0065, obrigada)      (0.0067, casa)   \n",
       "5        (0.0065, dia)         (0.0052, grande)  (0.0064, obrigada)   \n",
       "6       (0.0065, deus)        (0.0050, abencoe)       (0.0063, dia)   \n",
       "7       (0.0065, amor)          (0.0048, gente)      (0.0063, deus)   \n",
       "8  (0.0054, excelente)         (0.0048, doutor)      (0.0061, dias)   \n",
       "9     (0.0047, adorei)          (0.0047, saude)    (0.0055, senhor)   \n",
       "\n",
       "  Julio Pereira - Neurocirurgião              Lucy Kerr  \n",
       "0                 (0.0226, dias)  (0.0160, ivermectina)  \n",
       "1                 (0.0161, deus)         (0.0136, dias)  \n",
       "2               (0.0158, olfato)          (0.0128, dra)  \n",
       "3              (0.0154, paladar)        (0.0102, tomar)  \n",
       "4               (0.0151, cheiro)         (0.0102, deus)  \n",
       "5                  (0.0136, dor)           (0.0069, dr)  \n",
       "6                (0.0109, sinto)           (0.0067, 15)  \n",
       "7             (0.0094, sintomas)        (0.0065, covid)  \n",
       "8                (0.0092, gosto)         (0.0055, pode)  \n",
       "9               (0.0091, sentir)      (0.0053, pessoas)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel_F, stop_words=stop_words, binary=False)\n",
    "#Makes frequencies relative to each channel so that we have the probability distribution of words for each channel\n",
    "X = (X.T / X.sum(axis=1)).T\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "print('Palavras com maior frequência relativa entre mulheres em cada canal:')\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras com maior frequência relativa entre homens em cada canal:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0229, dias)</td>\n",
       "      <td>(0.0140, ivermectina)</td>\n",
       "      <td>(0.0247, dor)</td>\n",
       "      <td>(0.0184, sr)</td>\n",
       "      <td>(0.0230, dr)</td>\n",
       "      <td>(0.0092, virus)</td>\n",
       "      <td>(0.0205, dias)</td>\n",
       "      <td>(0.0175, ivermectina)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0149, comprimidos)</td>\n",
       "      <td>(0.0126, dr)</td>\n",
       "      <td>(0.0234, dia)</td>\n",
       "      <td>(0.0161, parabens)</td>\n",
       "      <td>(0.0130, virus)</td>\n",
       "      <td>(0.0088, video)</td>\n",
       "      <td>(0.0145, cheiro)</td>\n",
       "      <td>(0.0106, dias)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0138, tomar)</td>\n",
       "      <td>(0.0119, dias)</td>\n",
       "      <td>(0.0208, dias)</td>\n",
       "      <td>(0.0138, mundo)</td>\n",
       "      <td>(0.0079, saude)</td>\n",
       "      <td>(0.0082, dr)</td>\n",
       "      <td>(0.0141, olfato)</td>\n",
       "      <td>(0.0098, dra)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0132, ivermectina)</td>\n",
       "      <td>(0.0088, parabens)</td>\n",
       "      <td>(0.0169, virus)</td>\n",
       "      <td>(0.0138, entrevista)</td>\n",
       "      <td>(0.0056, video)</td>\n",
       "      <td>(0.0071, pessoas)</td>\n",
       "      <td>(0.0134, paladar)</td>\n",
       "      <td>(0.0077, comprimidos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0119, kg)</td>\n",
       "      <td>(0.0087, tomar)</td>\n",
       "      <td>(0.0143, sintomas)</td>\n",
       "      <td>(0.0115, mundial)</td>\n",
       "      <td>(0.0053, pessoas)</td>\n",
       "      <td>(0.0046, senhor)</td>\n",
       "      <td>(0.0117, deus)</td>\n",
       "      <td>(0.0071, tomar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0093, dr)</td>\n",
       "      <td>(0.0064, pessoas)</td>\n",
       "      <td>(0.0143, positivo)</td>\n",
       "      <td>(0.0115, farsa)</td>\n",
       "      <td>(0.0048, deus)</td>\n",
       "      <td>(0.0044, pode)</td>\n",
       "      <td>(0.0096, sentir)</td>\n",
       "      <td>(0.0058, covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0079, pode)</td>\n",
       "      <td>(0.0064, dose)</td>\n",
       "      <td>(0.0143, pode)</td>\n",
       "      <td>(0.0092, china)</td>\n",
       "      <td>(0.0046, senhor)</td>\n",
       "      <td>(0.0044, casa)</td>\n",
       "      <td>(0.0093, gosto)</td>\n",
       "      <td>(0.0054, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0079, durante)</td>\n",
       "      <td>(0.0062, 15)</td>\n",
       "      <td>(0.0143, deu)</td>\n",
       "      <td>(0.0092, brasil)</td>\n",
       "      <td>(0.0044, mundo)</td>\n",
       "      <td>(0.0043, doutor)</td>\n",
       "      <td>(0.0087, dia)</td>\n",
       "      <td>(0.0053, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0071, covid)</td>\n",
       "      <td>(0.0059, covid)</td>\n",
       "      <td>(0.0143, covid)</td>\n",
       "      <td>(0.0069, virus)</td>\n",
       "      <td>(0.0044, china)</td>\n",
       "      <td>(0.0040, dia)</td>\n",
       "      <td>(0.0082, sinto)</td>\n",
       "      <td>(0.0052, pode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0070, tratamento)</td>\n",
       "      <td>(0.0057, doutor)</td>\n",
       "      <td>(0.0117, exame)</td>\n",
       "      <td>(0.0069, vamos)</td>\n",
       "      <td>(0.0041, covid)</td>\n",
       "      <td>(0.0040, brasil)</td>\n",
       "      <td>(0.0079, covid)</td>\n",
       "      <td>(0.0051, tratamento)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dr. Alain Dutra      Dr. Alvaro Galvão Dr. Felipe Ades MD PhD  \\\n",
       "0         (0.0229, dias)  (0.0140, ivermectina)          (0.0247, dor)   \n",
       "1  (0.0149, comprimidos)           (0.0126, dr)          (0.0234, dia)   \n",
       "2        (0.0138, tomar)         (0.0119, dias)         (0.0208, dias)   \n",
       "3  (0.0132, ivermectina)     (0.0088, parabens)        (0.0169, virus)   \n",
       "4           (0.0119, kg)        (0.0087, tomar)     (0.0143, sintomas)   \n",
       "5           (0.0093, dr)      (0.0064, pessoas)     (0.0143, positivo)   \n",
       "6         (0.0079, pode)         (0.0064, dose)         (0.0143, pode)   \n",
       "7      (0.0079, durante)           (0.0062, 15)          (0.0143, deu)   \n",
       "8        (0.0071, covid)        (0.0059, covid)        (0.0143, covid)   \n",
       "9   (0.0070, tratamento)       (0.0057, doutor)        (0.0117, exame)   \n",
       "\n",
       "     Dr. Fernando Gomes Dr. Lair Ribeiro Oficial    Drauzio Varella  \\\n",
       "0          (0.0184, sr)             (0.0230, dr)    (0.0092, virus)   \n",
       "1    (0.0161, parabens)          (0.0130, virus)    (0.0088, video)   \n",
       "2       (0.0138, mundo)          (0.0079, saude)       (0.0082, dr)   \n",
       "3  (0.0138, entrevista)          (0.0056, video)  (0.0071, pessoas)   \n",
       "4     (0.0115, mundial)        (0.0053, pessoas)   (0.0046, senhor)   \n",
       "5       (0.0115, farsa)           (0.0048, deus)     (0.0044, pode)   \n",
       "6       (0.0092, china)         (0.0046, senhor)     (0.0044, casa)   \n",
       "7      (0.0092, brasil)          (0.0044, mundo)   (0.0043, doutor)   \n",
       "8       (0.0069, virus)          (0.0044, china)      (0.0040, dia)   \n",
       "9       (0.0069, vamos)          (0.0041, covid)   (0.0040, brasil)   \n",
       "\n",
       "  Julio Pereira - Neurocirurgião              Lucy Kerr  \n",
       "0                 (0.0205, dias)  (0.0175, ivermectina)  \n",
       "1               (0.0145, cheiro)         (0.0106, dias)  \n",
       "2               (0.0141, olfato)          (0.0098, dra)  \n",
       "3              (0.0134, paladar)  (0.0077, comprimidos)  \n",
       "4                 (0.0117, deus)        (0.0071, tomar)  \n",
       "5               (0.0096, sentir)        (0.0058, covid)  \n",
       "6                (0.0093, gosto)         (0.0054, deus)  \n",
       "7                  (0.0087, dia)           (0.0053, dr)  \n",
       "8                (0.0082, sinto)         (0.0052, pode)  \n",
       "9                (0.0079, covid)   (0.0051, tratamento)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel_M, stop_words=stop_words, binary=False)\n",
    "#Makes frequencies relative to each channel so that we have the probability distribution of words for each channel\n",
    "X = (X.T / X.sum(axis=1)).T\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "print('Palavras com maior frequência relativa entre homens em cada canal:')\n",
    "df_freq.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ic)",
   "language": "python",
   "name": "ic-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
