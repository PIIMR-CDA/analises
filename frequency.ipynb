{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_occurence_matrix(text, target=None, stop_words=None, binary=True, preprocess_text=False):  \n",
    "    '''\n",
    "    Output is messages x (unique) words\n",
    "    \n",
    "    If binary=True, then each element represents if the word is in the message or not.\n",
    "    Otherwise, it represents the count of how many times that word appears in that message.\n",
    "    ''' \n",
    "    if target:\n",
    "        text = list(filter(lambda x : target in x, text)) #Filter comments in which target word is present\n",
    "        \n",
    "    preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor()   \n",
    "    if stop_words:        \n",
    "        stop_words = [preprocessor(word) for word in stop_words] #preprocesses stop words\n",
    "    if preprocess_text:\n",
    "        text = [preprocessor(msg) for msg in text] #preprocesses text\n",
    "        \n",
    "    #calculates word count for each message\n",
    "    vectorizer = CountVectorizer(strip_accents='unicode', stop_words=stop_words, binary=binary)\n",
    "    X = vectorizer.fit_transform(text).toarray()\n",
    "    \n",
    "    labels = vectorizer.get_feature_names()\n",
    "    \n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('../comentarios_sorted_votes.csv')\n",
    "stop_words = [word.rstrip() for word in open('stopwords.txt')]\n",
    "\n",
    "#Preprocesses text\n",
    "preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor() #lowercase and strip accents\n",
    "stop_words = [preprocessor(word) for word in stop_words]\n",
    "comments['text'] = [preprocessor(msg) for msg in comments['text']]\n",
    "comments['text'] = [' '.join([word for word in RegexpTokenizer(r'\\w+').tokenize(msg) if not word in stop_words])\n",
    "                    for msg in comments['text']]\n",
    "\n",
    "N = 30 #Consider only the N most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_by_channel = []\n",
    "channels = []\n",
    "for channel, group in comments.groupby('uploader'):\n",
    "    channel_comments = ' '.join(group['text'])\n",
    "    comments_by_channel.append(channel_comments)\n",
    "    channels.append(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencia relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Em relação ao total\n",
    "Aqui foi usada a distribuição de probabilidade conjunta das palavras e canais, i.e., $p(a_i, c_j) = P(A=a_i, C= C_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice de exemplo do df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19afarsadadecada</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid2019tr</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid_19</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Dr. Alain Dutra  Dr. Alvaro Galvão  \\\n",
       "covid                         0.000620           0.000159   \n",
       "covid19                       0.000062           0.000009   \n",
       "covid19afarsadadecada         0.000000           0.000000   \n",
       "covid2019tr                   0.000000           0.000000   \n",
       "covid_19                      0.000001           0.000000   \n",
       "\n",
       "                       Dr. Felipe Ades MD PhD  Dr. Fernando Gomes  \\\n",
       "covid                                0.000059            0.000006   \n",
       "covid19                              0.000002            0.000002   \n",
       "covid19afarsadadecada                0.000000            0.000000   \n",
       "covid2019tr                          0.000000            0.000000   \n",
       "covid_19                             0.000000            0.000000   \n",
       "\n",
       "                       Dr. Lair Ribeiro Oficial  Drauzio Varella  \\\n",
       "covid                                  0.000090         0.000912   \n",
       "covid19                                0.000008         0.000122   \n",
       "covid19afarsadadecada                  0.000004         0.000000   \n",
       "covid2019tr                            0.000000         0.000000   \n",
       "covid_19                               0.000000         0.000001   \n",
       "\n",
       "                       Julio Pereira - Neurocirurgião  Lucy Kerr  \n",
       "covid                                        0.001879   0.000897  \n",
       "covid19                                      0.000191   0.000104  \n",
       "covid19afarsadadecada                        0.000000   0.000000  \n",
       "covid2019tr                                  0.000001   0.000000  \n",
       "covid_19                                     0.000000   0.000001  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "\n",
    "X = X / X.sum()\n",
    "df_total = pd.DataFrame(X.T, columns = channels, index = labels, dtype='float')\n",
    "print('Slice de exemplo do df:')\n",
    "df_total[12080:12085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Em relação ao canal\n",
    "Foi obtida a distribuição de probabilidade das palavras em cada canal $C_k$, i.e., $p(a_i|C_k) = P(A=a_i|C_k)$. \n",
    "Com isso, podemos fazer corretamente comparações entre os canais. Foram, então, selecionadas as palavras cuja ocorrência mais se difere entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice de exemplo do df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr. Alain Dutra</th>\n",
       "      <th>Dr. Alvaro Galvão</th>\n",
       "      <th>Dr. Felipe Ades MD PhD</th>\n",
       "      <th>Dr. Fernando Gomes</th>\n",
       "      <th>Dr. Lair Ribeiro Oficial</th>\n",
       "      <th>Drauzio Varella</th>\n",
       "      <th>Julio Pereira - Neurocirurgião</th>\n",
       "      <th>Lucy Kerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19afarsadadecada</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid2019tr</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid_19</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Dr. Alain Dutra  Dr. Alvaro Galvão  \\\n",
       "covid                         0.000620           0.000159   \n",
       "covid19                       0.000062           0.000009   \n",
       "covid19afarsadadecada         0.000000           0.000000   \n",
       "covid2019tr                   0.000000           0.000000   \n",
       "covid_19                      0.000001           0.000000   \n",
       "\n",
       "                       Dr. Felipe Ades MD PhD  Dr. Fernando Gomes  \\\n",
       "covid                                0.000059            0.000006   \n",
       "covid19                              0.000002            0.000002   \n",
       "covid19afarsadadecada                0.000000            0.000000   \n",
       "covid2019tr                          0.000000            0.000000   \n",
       "covid_19                             0.000000            0.000000   \n",
       "\n",
       "                       Dr. Lair Ribeiro Oficial  Drauzio Varella  \\\n",
       "covid                                  0.000090         0.000912   \n",
       "covid19                                0.000008         0.000122   \n",
       "covid19afarsadadecada                  0.000004         0.000000   \n",
       "covid2019tr                            0.000000         0.000000   \n",
       "covid_19                               0.000000         0.000001   \n",
       "\n",
       "                       Julio Pereira - Neurocirurgião  Lucy Kerr  \n",
       "covid                                        0.001879   0.000897  \n",
       "covid19                                      0.000191   0.000104  \n",
       "covid19afarsadadecada                        0.000000   0.000000  \n",
       "covid2019tr                                  0.000001   0.000000  \n",
       "covid_19                                     0.000000   0.000001  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "#Makes frequencies relative to each channel so that we have the probability distribution of words for each channel\n",
    "X = (X.T / X.sum(axis=1)).T\n",
    "df_canal = pd.DataFrame(X.T, columns = channels, index = labels)\n",
    "print('Slice de exemplo do df:')\n",
    "df_total[12080:12085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ic)",
   "language": "python",
   "name": "ic-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
