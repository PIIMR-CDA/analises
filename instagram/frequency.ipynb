{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_occurence_matrix(text, target=None, stop_words=None, binary=True, preprocess_text=False):  \n",
    "    '''\n",
    "    Output is messages x (unique) words\n",
    "    \n",
    "    If binary=True, then each element represents if the word is in the message or not.\n",
    "    Otherwise, it represents the count of how many times that word appears in that message.\n",
    "    ''' \n",
    "    if target:\n",
    "        text = list(filter(lambda x : target in x, text)) #Filter comments in which target word is present\n",
    "        \n",
    "    preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor()   \n",
    "    if stop_words:        \n",
    "        stop_words = [preprocessor(word) for word in stop_words] #preprocesses stop words\n",
    "    if preprocess_text:\n",
    "        text = [preprocessor(msg) for msg in text] #preprocesses text\n",
    "        \n",
    "    #calculates word count for each message\n",
    "    vectorizer = CountVectorizer(strip_accents='unicode', stop_words=stop_words, binary=binary)\n",
    "    X = vectorizer.fit_transform(text).toarray()\n",
    "    \n",
    "    labels = vectorizer.get_feature_names()\n",
    "    \n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('../../dados/instagram/filtered_comments.csv')\n",
    "stop_words = [word.rstrip() for word in open('../stopwords.txt')]\n",
    "\n",
    "preprocessor = CountVectorizer(strip_accents='unicode').build_preprocessor() \n",
    "#lowercase and strip accents\n",
    "stop_words = [preprocessor(word) for word in stop_words]\n",
    "#English and Spanish Words\n",
    "stop_words.extend(['you', 'good', 'the', 'to', 'live', 'very', 'your', 'work', 'is', 'my', 'from', 'love', 'and', \n",
    "                   'in', 'thank', 'informative', 'are', 'of', 'un', 'english', 'what', 'mi', 'hello', 'el', \n",
    "                   'but', 'doctor'])\n",
    "#Nomes Próprios\n",
    "stop_words.extend(['drauzio', 'varella', 'lucy', 'kerr', 'julio', 'pereira','fernando', 'pinto', 'gomes', 'lair', \n",
    "                   'ribeiro', 'alvaro', 'galvao', 'felipe', 'ades', 'gomez', 'alain', 'dutra'])\n",
    "#Pronomes e preposições\n",
    "stop_words.extend(['pra', 'vc', 'todos', 'tudo', 'cada', 'nada', 'sobre'])\n",
    "#Conjunções\n",
    "stop_words.extend(['porque', 'pois', 'pq'])\n",
    "#Advérbios\n",
    "stop_words.extend(['assim', 'bem', 'ainda', 'agora', 'sim', 'sempre', 'aqui', 'la', 'tbm', 'ai', 'hoje'])\n",
    "#Verbos frequentes\n",
    "stop_words.extend(['vai', 'ser', 'ter', 'ta', 'fazer', 'fiz', 'faz', 'vou'])\n",
    "#Outros\n",
    "stop_words.extend(['boa', 'bom', 'obrigado', 'ola'])\n",
    "\n",
    "#Remove urls\n",
    "comments['texto_do_comentario'] = [re.sub(r'http\\S+', '', msg) for msg in comments['texto_do_comentario']]\n",
    "#Remove emails\n",
    "comments['texto_do_comentario'] = [re.sub(r'\\S*@\\S*\\s?', '', msg) for msg in comments['texto_do_comentario']]\n",
    "#lowercase and strip accents\n",
    "comments['texto_do_comentario'] = [preprocessor(msg) for msg in comments['texto_do_comentario']]\n",
    "#remove stopwords and punctuation\n",
    "comments['texto_do_comentario'] = [' '.join([word for word in RegexpTokenizer(r'\\w+').tokenize(msg) \n",
    "                                             if not word in stop_words])\n",
    "                                  for msg in comments['texto_do_comentario']]\n",
    "# Remove new line characters\n",
    "comments['texto_do_comentario'] = [re.sub(r'\\s+', ' ', msg) for msg in comments['texto_do_comentario']]\n",
    "# Remove distracting single quotes\n",
    "comments['texto_do_comentario'] = [re.sub(r\"\\'\", \"\", msg) for msg in comments['texto_do_comentario']]\n",
    "#Remove special characters\n",
    "comments['texto_do_comentario'] = [re.sub(r'([^a-zA-Z0-9\\s]+?)', '', msg) for msg in comments['texto_do_comentario']]\n",
    "\n",
    "#Remove words with freq == 1\n",
    "fdist = FreqDist(RegexpTokenizer(r'\\w+').tokenize(' '.join(comments['texto_do_comentario'])))\n",
    "freq_filter = filter(lambda x: x[1] == 1, fdist.items())\n",
    "fdist = [t[0] for t in freq_filter]\n",
    "comments['texto_do_comentario'] = [' '.join([word for word in RegexpTokenizer(r'\\w+').tokenize(msg) \n",
    "                                             if not word in fdist])\n",
    "                                  for msg in comments['texto_do_comentario']]\n",
    "\n",
    "N = 30 #Consider only the N most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_by_channel = []\n",
    "channels = []\n",
    "for channel, group in comments.groupby('dono_do_post'):\n",
    "    channel_comments = ' '.join(group['texto_do_comentario'])\n",
    "    comments_by_channel.append(channel_comments)\n",
    "    channels.append(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencia relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Em relação ao total\n",
    "Não usar essa. Deixei aqui por precaução.\n",
    "\n",
    "Aqui foi usada a distribuição de probabilidade conjunta das palavras e canais, i.e., $p(a_i, c_j) = P(A=a_i, C= C_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr.galvao</th>\n",
       "      <th>dralaindutra</th>\n",
       "      <th>drfelipeades</th>\n",
       "      <th>drfernandoneuro</th>\n",
       "      <th>drlairribeiro</th>\n",
       "      <th>imedlkep</th>\n",
       "      <th>juliommais</th>\n",
       "      <th>sitedrauziovarella</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0001, parabens)</td>\n",
       "      <td>(0.0007, vitamina)</td>\n",
       "      <td>(0.0002, dr)</td>\n",
       "      <td>(0.0140, dr)</td>\n",
       "      <td>(0.0010, dr)</td>\n",
       "      <td>(0.0003, tomar)</td>\n",
       "      <td>(0.0001, parabens)</td>\n",
       "      <td>(0.0064, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0001, dr)</td>\n",
       "      <td>(0.0007, dr)</td>\n",
       "      <td>(0.0001, virus)</td>\n",
       "      <td>(0.0055, dia)</td>\n",
       "      <td>(0.0003, saude)</td>\n",
       "      <td>(0.0003, ivermectina)</td>\n",
       "      <td>(0.0001, deus)</td>\n",
       "      <td>(0.0042, obrigada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0000, zycze)</td>\n",
       "      <td>(0.0005, tomar)</td>\n",
       "      <td>(0.0001, uso)</td>\n",
       "      <td>(0.0038, deus)</td>\n",
       "      <td>(0.0002, virus)</td>\n",
       "      <td>(0.0003, dra)</td>\n",
       "      <td>(0.0000, zycze)</td>\n",
       "      <td>(0.0031, pessoas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0000, zyciu)</td>\n",
       "      <td>(0.0004, pode)</td>\n",
       "      <td>(0.0001, triste)</td>\n",
       "      <td>(0.0037, parabens)</td>\n",
       "      <td>(0.0002, sistema)</td>\n",
       "      <td>(0.0002, dose)</td>\n",
       "      <td>(0.0000, zyciu)</td>\n",
       "      <td>(0.0031, casa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0000, zycie)</td>\n",
       "      <td>(0.0004, obrigada)</td>\n",
       "      <td>(0.0001, tratamento)</td>\n",
       "      <td>(0.0027, lindo)</td>\n",
       "      <td>(0.0002, senhor)</td>\n",
       "      <td>(0.0002, dias)</td>\n",
       "      <td>(0.0000, zycie)</td>\n",
       "      <td>(0.0029, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0000, zyc)</td>\n",
       "      <td>(0.0004, dias)</td>\n",
       "      <td>(0.0001, tomar)</td>\n",
       "      <td>(0.0027, it)</td>\n",
       "      <td>(0.0002, obrigada)</td>\n",
       "      <td>(0.0001, video)</td>\n",
       "      <td>(0.0000, zyc)</td>\n",
       "      <td>(0.0025, pode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0000, zwei)</td>\n",
       "      <td>(0.0003, sol)</td>\n",
       "      <td>(0.0001, saber)</td>\n",
       "      <td>(0.0026, noite)</td>\n",
       "      <td>(0.0002, melhor)</td>\n",
       "      <td>(0.0001, uso)</td>\n",
       "      <td>(0.0000, zwei)</td>\n",
       "      <td>(0.0024, video)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0000, zusammen)</td>\n",
       "      <td>(0.0003, saude)</td>\n",
       "      <td>(0.0001, risco)</td>\n",
       "      <td>(0.0022, doutor)</td>\n",
       "      <td>(0.0002, medico)</td>\n",
       "      <td>(0.0001, unica)</td>\n",
       "      <td>(0.0000, zusammen)</td>\n",
       "      <td>(0.0024, senhor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0000, zur)</td>\n",
       "      <td>(0.0003, pessoas)</td>\n",
       "      <td>(0.0001, pode)</td>\n",
       "      <td>(0.0021, that)</td>\n",
       "      <td>(0.0002, imunidade)</td>\n",
       "      <td>(0.0001, tratamento)</td>\n",
       "      <td>(0.0000, zur)</td>\n",
       "      <td>(0.0018, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0000, zumbido)</td>\n",
       "      <td>(0.0003, parabens)</td>\n",
       "      <td>(0.0001, pessoas)</td>\n",
       "      <td>(0.0020, we)</td>\n",
       "      <td>(0.0002, falar)</td>\n",
       "      <td>(0.0001, tomei)</td>\n",
       "      <td>(0.0000, zumbido)</td>\n",
       "      <td>(0.0017, saude)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dr.galvao        dralaindutra          drfelipeades  \\\n",
       "0  (0.0001, parabens)  (0.0007, vitamina)          (0.0002, dr)   \n",
       "1        (0.0001, dr)        (0.0007, dr)       (0.0001, virus)   \n",
       "2     (0.0000, zycze)     (0.0005, tomar)         (0.0001, uso)   \n",
       "3     (0.0000, zyciu)      (0.0004, pode)      (0.0001, triste)   \n",
       "4     (0.0000, zycie)  (0.0004, obrigada)  (0.0001, tratamento)   \n",
       "5       (0.0000, zyc)      (0.0004, dias)       (0.0001, tomar)   \n",
       "6      (0.0000, zwei)       (0.0003, sol)       (0.0001, saber)   \n",
       "7  (0.0000, zusammen)     (0.0003, saude)       (0.0001, risco)   \n",
       "8       (0.0000, zur)   (0.0003, pessoas)        (0.0001, pode)   \n",
       "9   (0.0000, zumbido)  (0.0003, parabens)     (0.0001, pessoas)   \n",
       "\n",
       "      drfernandoneuro        drlairribeiro               imedlkep  \\\n",
       "0        (0.0140, dr)         (0.0010, dr)        (0.0003, tomar)   \n",
       "1       (0.0055, dia)      (0.0003, saude)  (0.0003, ivermectina)   \n",
       "2      (0.0038, deus)      (0.0002, virus)          (0.0003, dra)   \n",
       "3  (0.0037, parabens)    (0.0002, sistema)         (0.0002, dose)   \n",
       "4     (0.0027, lindo)     (0.0002, senhor)         (0.0002, dias)   \n",
       "5        (0.0027, it)   (0.0002, obrigada)        (0.0001, video)   \n",
       "6     (0.0026, noite)     (0.0002, melhor)          (0.0001, uso)   \n",
       "7    (0.0022, doutor)     (0.0002, medico)        (0.0001, unica)   \n",
       "8      (0.0021, that)  (0.0002, imunidade)   (0.0001, tratamento)   \n",
       "9        (0.0020, we)      (0.0002, falar)        (0.0001, tomei)   \n",
       "\n",
       "           juliommais  sitedrauziovarella  \n",
       "0  (0.0001, parabens)        (0.0064, dr)  \n",
       "1      (0.0001, deus)  (0.0042, obrigada)  \n",
       "2     (0.0000, zycze)   (0.0031, pessoas)  \n",
       "3     (0.0000, zyciu)      (0.0031, casa)  \n",
       "4     (0.0000, zycie)     (0.0029, virus)  \n",
       "5       (0.0000, zyc)      (0.0025, pode)  \n",
       "6      (0.0000, zwei)     (0.0024, video)  \n",
       "7  (0.0000, zusammen)    (0.0024, senhor)  \n",
       "8       (0.0000, zur)      (0.0018, deus)  \n",
       "9   (0.0000, zumbido)     (0.0017, saude)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "\n",
    "X = X / X.sum()\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 palavras com maior desvio padrão entre os canais:\n",
      "\n",
      "[('dr', '0.0047'), ('dia', '0.0018'), ('obrigada', '0.0014'), ('deus', '0.0013'), ('parabens', '0.0012'), ('pessoas', '0.0010'), ('casa', '0.0010'), ('virus', '0.0010'), ('it', '0.0009'), ('lindo', '0.0009'), ('noite', '0.0008'), ('senhor', '0.0008'), ('pode', '0.0008'), ('video', '0.0008'), ('doutor', '0.0008'), ('that', '0.0007'), ('we', '0.0007'), ('saude', '0.0006'), ('all', '0.0006'), ('this', '0.0006'), ('have', '0.0006'), ('with', '0.0006'), ('be', '0.0006'), ('abencoe', '0.0006'), ('medico', '0.0005'), ('amo', '0.0005'), ('gente', '0.0005'), ('covid', '0.0005'), ('dias', '0.0005'), ('tarde', '0.0005')]\n"
     ]
    }
   ],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Em relação ao canal\n",
    "Foi obtida a distribuição de probabilidade das palavras em cada canal $C_k$, i.e., $p(a_i|C_k) = P(A=a_i|C_k)$. \n",
    "Com isso, podemos fazer corretamente comparações entre os canais. Foram, então, selecionadas as palavras cuja ocorrência mais se difere entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras com maior frequência relativa em cada canal:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr.galvao</th>\n",
       "      <th>dralaindutra</th>\n",
       "      <th>drfelipeades</th>\n",
       "      <th>drfernandoneuro</th>\n",
       "      <th>drlairribeiro</th>\n",
       "      <th>imedlkep</th>\n",
       "      <th>juliommais</th>\n",
       "      <th>sitedrauziovarella</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0362, parabens)</td>\n",
       "      <td>(0.0129, dr)</td>\n",
       "      <td>(0.0158, dr)</td>\n",
       "      <td>(0.0309, dr)</td>\n",
       "      <td>(0.0304, dr)</td>\n",
       "      <td>(0.0200, tomar)</td>\n",
       "      <td>(0.0822, deus)</td>\n",
       "      <td>(0.0150, dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0362, dr)</td>\n",
       "      <td>(0.0125, vitamina)</td>\n",
       "      <td>(0.0129, deus)</td>\n",
       "      <td>(0.0121, dia)</td>\n",
       "      <td>(0.0093, saude)</td>\n",
       "      <td>(0.0185, dra)</td>\n",
       "      <td>(0.0789, parabens)</td>\n",
       "      <td>(0.0099, obrigada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0125, 15)</td>\n",
       "      <td>(0.0086, tomar)</td>\n",
       "      <td>(0.0120, triste)</td>\n",
       "      <td>(0.0084, deus)</td>\n",
       "      <td>(0.0079, deus)</td>\n",
       "      <td>(0.0178, ivermectina)</td>\n",
       "      <td>(0.0362, abencoe)</td>\n",
       "      <td>(0.0073, pessoas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0111, medico)</td>\n",
       "      <td>(0.0074, dias)</td>\n",
       "      <td>(0.0109, pessoas)</td>\n",
       "      <td>(0.0081, parabens)</td>\n",
       "      <td>(0.0070, imunidade)</td>\n",
       "      <td>(0.0127, dias)</td>\n",
       "      <td>(0.0263, saude)</td>\n",
       "      <td>(0.0072, casa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0111, excelente)</td>\n",
       "      <td>(0.0070, obrigada)</td>\n",
       "      <td>(0.0091, risco)</td>\n",
       "      <td>(0.0060, lindo)</td>\n",
       "      <td>(0.0068, obrigada)</td>\n",
       "      <td>(0.0122, dose)</td>\n",
       "      <td>(0.0263, continue)</td>\n",
       "      <td>(0.0068, virus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0084, ji)</td>\n",
       "      <td>(0.0065, pode)</td>\n",
       "      <td>(0.0088, tratamento)</td>\n",
       "      <td>(0.0060, it)</td>\n",
       "      <td>(0.0065, melhor)</td>\n",
       "      <td>(0.0089, pode)</td>\n",
       "      <td>(0.0197, feliz)</td>\n",
       "      <td>(0.0058, pode)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0084, doutor)</td>\n",
       "      <td>(0.0059, sol)</td>\n",
       "      <td>(0.0088, casa)</td>\n",
       "      <td>(0.0057, noite)</td>\n",
       "      <td>(0.0062, virus)</td>\n",
       "      <td>(0.0089, covid)</td>\n",
       "      <td>(0.0197, aniversario)</td>\n",
       "      <td>(0.0057, senhor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0084, deus)</td>\n",
       "      <td>(0.0059, dia)</td>\n",
       "      <td>(0.0070, parabens)</td>\n",
       "      <td>(0.0048, doutor)</td>\n",
       "      <td>(0.0058, sistema)</td>\n",
       "      <td>(0.0077, comprimidos)</td>\n",
       "      <td>(0.0164, abencoando)</td>\n",
       "      <td>(0.0056, video)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0070, video)</td>\n",
       "      <td>(0.0055, dose)</td>\n",
       "      <td>(0.0068, pode)</td>\n",
       "      <td>(0.0047, that)</td>\n",
       "      <td>(0.0052, falar)</td>\n",
       "      <td>(0.0075, video)</td>\n",
       "      <td>(0.0132, vida)</td>\n",
       "      <td>(0.0042, deus)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.0070, pessoa)</td>\n",
       "      <td>(0.0052, pessoas)</td>\n",
       "      <td>(0.0068, grupo)</td>\n",
       "      <td>(0.0044, we)</td>\n",
       "      <td>(0.0051, senhor)</td>\n",
       "      <td>(0.0073, deus)</td>\n",
       "      <td>(0.0132, proteja)</td>\n",
       "      <td>(0.0040, saude)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr.galvao        dralaindutra          drfelipeades  \\\n",
       "0   (0.0362, parabens)        (0.0129, dr)          (0.0158, dr)   \n",
       "1         (0.0362, dr)  (0.0125, vitamina)        (0.0129, deus)   \n",
       "2         (0.0125, 15)     (0.0086, tomar)      (0.0120, triste)   \n",
       "3     (0.0111, medico)      (0.0074, dias)     (0.0109, pessoas)   \n",
       "4  (0.0111, excelente)  (0.0070, obrigada)       (0.0091, risco)   \n",
       "5         (0.0084, ji)      (0.0065, pode)  (0.0088, tratamento)   \n",
       "6     (0.0084, doutor)       (0.0059, sol)        (0.0088, casa)   \n",
       "7       (0.0084, deus)       (0.0059, dia)    (0.0070, parabens)   \n",
       "8      (0.0070, video)      (0.0055, dose)        (0.0068, pode)   \n",
       "9     (0.0070, pessoa)   (0.0052, pessoas)       (0.0068, grupo)   \n",
       "\n",
       "      drfernandoneuro        drlairribeiro               imedlkep  \\\n",
       "0        (0.0309, dr)         (0.0304, dr)        (0.0200, tomar)   \n",
       "1       (0.0121, dia)      (0.0093, saude)          (0.0185, dra)   \n",
       "2      (0.0084, deus)       (0.0079, deus)  (0.0178, ivermectina)   \n",
       "3  (0.0081, parabens)  (0.0070, imunidade)         (0.0127, dias)   \n",
       "4     (0.0060, lindo)   (0.0068, obrigada)         (0.0122, dose)   \n",
       "5        (0.0060, it)     (0.0065, melhor)         (0.0089, pode)   \n",
       "6     (0.0057, noite)      (0.0062, virus)        (0.0089, covid)   \n",
       "7    (0.0048, doutor)    (0.0058, sistema)  (0.0077, comprimidos)   \n",
       "8      (0.0047, that)      (0.0052, falar)        (0.0075, video)   \n",
       "9        (0.0044, we)     (0.0051, senhor)         (0.0073, deus)   \n",
       "\n",
       "              juliommais  sitedrauziovarella  \n",
       "0         (0.0822, deus)        (0.0150, dr)  \n",
       "1     (0.0789, parabens)  (0.0099, obrigada)  \n",
       "2      (0.0362, abencoe)   (0.0073, pessoas)  \n",
       "3        (0.0263, saude)      (0.0072, casa)  \n",
       "4     (0.0263, continue)     (0.0068, virus)  \n",
       "5        (0.0197, feliz)      (0.0058, pode)  \n",
       "6  (0.0197, aniversario)    (0.0057, senhor)  \n",
       "7   (0.0164, abencoando)     (0.0056, video)  \n",
       "8         (0.0132, vida)      (0.0042, deus)  \n",
       "9      (0.0132, proteja)     (0.0040, saude)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, labels = word_occurence_matrix(comments_by_channel, stop_words=stop_words, binary=False)\n",
    "#Makes frequencies relative to each channel so that we have the probability distribution of words for each channel\n",
    "X = (X.T / X.sum(axis=1)).T\n",
    "\n",
    "freq_lists = [list(zip(['%.4f'%(freq) for freq in row],labels)) for row in X]\n",
    "freq_lists = [sorted(channel, reverse=True) for channel in freq_lists]\n",
    "df_freq = pd.DataFrame(freq_lists, index = channels).T\n",
    "\n",
    "print('Palavras com maior frequência relativa em cada canal:')\n",
    "df_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 palavras com maior desvio padrão entre os canais:\n",
      "\n",
      "[('parabens', '0.0255'), ('deus', '0.0248'), ('abencoe', '0.0112'), ('dr', '0.0110'), ('continue', '0.0085'), ('saude', '0.0075'), ('aniversario', '0.0065'), ('feliz', '0.0063'), ('tomar', '0.0063'), ('dra', '0.0061'), ('ivermectina', '0.0057'), ('abencoando', '0.0054'), ('felicidades', '0.0043'), ('dose', '0.0042'), ('proteja', '0.0042'), ('dias', '0.0040'), ('15', '0.0040'), ('vitamina', '0.0040'), ('triste', '0.0038'), ('vida', '0.0038'), ('excelente', '0.0034'), ('sucesso', '0.0031'), ('amigo', '0.0031'), ('dia', '0.0031'), ('pessoas', '0.0030'), ('senhor', '0.0030'), ('doutor', '0.0030'), ('grande', '0.0029'), ('video', '0.0029'), ('familia', '0.0029')]\n"
     ]
    }
   ],
   "source": [
    "#Selects only the N with higher std\n",
    "word_std = X.std(axis=0)\n",
    "higher_std_zipped = sorted(zip(word_std, labels, X.T), reverse=True)[:N]\n",
    "word_std, labels, X_t = zip(*higher_std_zipped)\n",
    "\n",
    "word_std_i = ['%.4f'%(x) for x in word_std]\n",
    "print(f'{N} palavras com maior desvio padrão entre os canais:\\n')\n",
    "print(list(zip(labels, word_std_i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ic)",
   "language": "python",
   "name": "ic-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
